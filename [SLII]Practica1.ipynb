{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "closing-still",
   "metadata": {},
   "source": [
    "## Practica 1 Stadistical Learning 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worst-feeding",
   "metadata": {},
   "source": [
    "**21000341 - Jherson Sazo**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revised-characterization",
   "metadata": {},
   "source": [
    "Descripción:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "isolated-message",
   "metadata": {},
   "source": [
    "Llenar información de estatura y edad en la pestaña normales(por favor llenar hoy mismo):  \n",
    "Datos\n",
    "* Utilizar estos datos(primera pestaña) para implementar :\n",
    "    * Hard-clustering con k-means (no usar sklearn)\n",
    "    * Soft-clustering con GMM usando sklearn(sklearn.mixture.GaussianMixture)\n",
    "* Ejecutar al menos 5 experimentos para seleccionar el valor de “K”\n",
    "    * Ambos métodos pueden usar el mismo valor de “K”\n",
    "    * Analizar el centroide de cada cluster y determinar si es posible asignar una categoría  cada cluster\n",
    "* Analizar y concluir si el método del codo es adecuado para este problema\n",
    "* Usar los datos en la segunda pestaña(valtest(normales)) y estimar:\n",
    "    * El cluster que k-means asigna cada uno.\n",
    "    * La probabilidad de pertenecer a cada cluster según GMM.\n",
    "* Usar GMM y simular 1000 observaciones para estimar(estimación de Monte Carlo) el valor esperado(promedio) de la función f   f(edad, estatura) = estatura /edad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fleet-error",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Import the necessary packages.\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "impressed-contest",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster = pd.read_csv('k-means clustering.csv') # Read data file into 'cluster'\n",
    "    #cluster = open_excel_by_sheetname('estaturas.xlsx',0) # Read data file into 'cluster'\n",
    "    #cluster.columns = ['x','y']\n",
    "data = open_excel_by_sheetname('estaturas.xlsx',0)\n",
    "data.columns = ['x','y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "pregnant-stable",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_k_means(cluster,k,number_of_iterations):\n",
    "    \n",
    "    rows = cluster.shape[0] # 'rows' contains the total number of rows in cluster data.\n",
    "    cols = cluster.shape[1] # 'cols' contains the total number of columns in cluster data.\n",
    "  \n",
    "    k_initializer = np.random.randint(1,rows,k)\n",
    "    centroids = cluster.loc[k_initializer] # Randomly initialises 'k' no. of centroids.\n",
    "\n",
    "    centroids['new'] = list(range(1,k+1)) # New indices 1 to k are set for the dataframe 'centroids'.\n",
    "    centroids.set_index('new',inplace = True) \n",
    "    d = np.random.rand(rows) # Initialization of 'd' which would contain the centroid number closest to data point.\n",
    "\n",
    "    #number_of_iterations = 15\n",
    "    temp_epsilon = list(range(number_of_iterations)) # 'temp_epsilon' is the sum of squares of distances between points and centroid of a cluster for each iteration.\n",
    "\n",
    "    for i in range(0,number_of_iterations): # This 'for' loop is for iterations.\n",
    "\n",
    "        for j in range(0,rows): # This 'for' loop finds the centroid number closest to the data point.\n",
    "            d[j] = ((centroids - cluster.loc[j])**2).sum(axis = 1).idxmin()\n",
    "        cluster['centroid number'] = d # A new column 'centroid number' is added to dataframe 'cluster'.\n",
    "\n",
    "        mean_x = list(range(k)) # Initialisation of 'mean_x' which will store mean of 'x' values of each cluster.\n",
    "        mean_y = list(range(k)) # Initialisation of 'mean_y' which will store mean of 'y' values of each cluster.\n",
    "        for m in range(0,k): # This 'for' loop calculates mean of 'x' and 'y' values of each cluster.\n",
    "            mean_x[m] = cluster[cluster['centroid number'] == (m+1)]['x'].mean()\n",
    "            mean_y[m] = cluster[cluster['centroid number'] == (m+1)]['y'].mean()\n",
    "        centroids.replace(list(centroids['x']),mean_x,inplace = True) # The 'centroids' are replaced with the new values.\n",
    "        centroids.replace(list(centroids['y']),mean_y,inplace = True)\n",
    "    \n",
    "        z = list(range(k)) # Initialisation of z  and centroid of each cluster.\n",
    "        for p in range(0,k): # This 'for' loop calculates square of distances between data points and centroid of each cluster.\n",
    "            z[p] = ((cluster[cluster['centroid number'] == p+1][['x','y']] - centroids.iloc[p])**2).values.sum()\n",
    "        temp_epsilon[i] = round(sum(z),4) \n",
    "        \n",
    "        if i > 0 and temp_epsilon[i-1] == temp_epsilon[i]:\n",
    "            print(\"SON los costos iguales??\",temp_epsilon[i-1],temp_epsilon[i])\n",
    "            return [cluster,centroids,temp_epsilon[i]]\n",
    "    print(\"LLEGO AL FINAL\")\n",
    "    return [cluster,centroids,temp_epsilon[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "isolated-shuttle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_excel_by_sheetname(full_path, name_sheet):\n",
    "    try:\n",
    "        df = pd.read_excel(full_path, sheet_name=name_sheet)\n",
    "        return df\n",
    "    except Exception as error:\n",
    "        raise error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "devoted-initial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SON los costos iguales?? 407.695 407.695\n",
      "[       x     y  centroid number\n",
      "0   1.77  26.0              2.0\n",
      "1   1.74  31.0              3.0\n",
      "2   1.72  24.0              2.0\n",
      "3   1.78  34.0              3.0\n",
      "4   1.65  32.0              4.0\n",
      "5   1.66  29.0              4.0\n",
      "6   1.64  27.0              4.0\n",
      "7   1.85  34.0              3.0\n",
      "8   1.85  26.0              2.0\n",
      "9   1.75  21.0              2.0\n",
      "10  1.73  23.0              2.0\n",
      "11  1.79  25.0              2.0\n",
      "12  1.82  24.0              2.0\n",
      "13  1.65  25.0              2.0\n",
      "14  1.79  25.0              2.0\n",
      "15  1.72  34.0              3.0\n",
      "16  1.70  26.0              2.0\n",
      "17  1.57  25.0              2.0\n",
      "18  1.66  26.0              2.0\n",
      "19  1.75  27.0              3.0\n",
      "20  1.77  32.0              3.0\n",
      "21  1.80  40.0              1.0\n",
      "22  1.85  25.0              2.0\n",
      "23  1.82  24.0              2.0\n",
      "24  1.75  38.0              1.0\n",
      "25  1.73  34.0              3.0\n",
      "26  1.55  29.0              4.0\n",
      "27  1.76  28.0              3.0\n",
      "28  1.68  27.0              4.0\n",
      "29  1.65  30.0              4.0\n",
      "30  1.72  26.0              2.0\n",
      "31  1.90  24.0              2.0\n",
      "32  1.74  34.0              3.0\n",
      "33  1.73  33.0              3.0\n",
      "34  1.83  53.0              1.0\n",
      "35  1.65  28.0              4.0\n",
      "36  1.73  24.0              2.0\n",
      "37  1.73  22.0              2.0\n",
      "38  1.73  23.0              2.0\n",
      "39  1.65  43.0              1.0\n",
      "40  1.72  26.0              2.0\n",
      "41  1.63  31.0              4.0\n",
      "42  1.73  35.0              3.0\n",
      "43  1.85  49.0              1.0\n",
      "44  1.71  28.0              3.0\n",
      "45  1.70  28.0              3.0,             x       y\n",
      "new                  \n",
      "1    1.776000  44.600\n",
      "2    1.750000  24.500\n",
      "3    1.746923  29.125\n",
      "4    1.638750  29.125, 407.695]\n"
     ]
    }
   ],
   "source": [
    "cluster = open_excel_by_sheetname('estaturas.xlsx',0) # Read data file into 'cluster'\n",
    "cluster.head()\n",
    "cluster.columns = ['x','y']\n",
    "print(train_k_means(cluster,4,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charged-inquiry",
   "metadata": {},
   "source": [
    "**Nota**:\n",
    "Haciendo varios experimentos, me he podido dar cuenta que el valor de costo varia en cada prueba con el mismo numero de K, esto se puede validar ejecutando varias veces las sentencias anteriores, debido a que los centros se obtienen de forma aleatoria, lo que genera estas variaciones.  \n",
    "\n",
    "Ante ello se puede hacer una mejora a este método haciendo iteraciones con el mismo valor de K, y posterior obtener los centroides con el costo mas bajo.\n",
    "\n",
    "La funcion codo, es iterar variando el numero de K para obtener los centroides con el costo mas bajo, pero esta funcionalidad se va ver reflejada en el siguiente metodo probando 5 valores de K, adicionando lo mencionado anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-sharing",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "center-auditor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "blind-stress",
   "metadata": {},
   "source": [
    "## Soft-clustering con GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "lightweight-wagon",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "atmospheric-singapore",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_GMM(data, K):\n",
    "    gm = GaussianMixture(n_components=K, random_state=0).fit(data)\n",
    "    gm.means_\n",
    "    return gm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "determined-convention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.72384042 25.89825759]\n",
      " [ 1.74628242 35.17238953]]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "#Experimento 1, 2 clusters\n",
    "gm = train_GMM(data,2)\n",
    "print(gm.means_)\n",
    "print(gm.predict([[1.70,28]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "random-cincinnati",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.72807829 25.58286677]\n",
      " [ 1.77666741 48.33323415]\n",
      " [ 1.73243803 33.4444868 ]]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "#Experimento 2, 3 clusters\n",
    "gm = train_GMM(data,3)\n",
    "print(gm.means_)\n",
    "print(gm.predict([[1.70,28]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "mental-virtue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.67056857 28.20035884]\n",
      " [ 1.77666859 48.33329889]\n",
      " [ 1.75158586 34.17089106]\n",
      " [ 1.7503387  24.65611208]]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "#Experimento 3, 4 clusters\n",
    "gm = train_GMM(data,4)\n",
    "print(gm.means_)\n",
    "print(gm.predict([[1.70,28]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "shared-reduction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.67897568 27.8123578 ]\n",
      " [ 1.84       51.        ]\n",
      " [ 1.73048713 32.97000029]\n",
      " [ 1.7478479  24.64599493]\n",
      " [ 1.73406862 40.29442874]]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "#Experimento 4, 5 clusters\n",
    "gm = train_GMM(data,5)\n",
    "print(gm.means_)\n",
    "print(gm.predict([[1.70,28]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "final-parcel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.7326087  29.52173913]]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "#Experimento 5, 1 clusters\n",
    "gm = train_GMM(data,1)\n",
    "print(gm.means_)\n",
    "print(gm.predict([[1.70,28]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exterior-lesson",
   "metadata": {},
   "source": [
    "**Calulando las predicciones del excel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "numerous-diagram",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Estatura(metros)  Edad(años)\n",
      "0              1.82        25.0\n",
      "1              1.80        27.0\n",
      "2              1.60        31.0\n",
      "3              1.60        35.0\n",
      "4              1.82        30.0\n",
      "5              1.76        32.0\n",
      "6              1.79        31.0\n",
      "[0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "test = open_excel_by_sheetname('estaturas.xlsx',1) # Read data file into 'cluster'\n",
    "print(test.head(7))\n",
    "predicts = gm.predict(test)\n",
    "print(predicts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-collection",
   "metadata": {},
   "source": [
    "**Estimar el metodo MonteCarlo con 1000 observaciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "industrial-translation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.78173549, 41.22736165],\n",
       "       [ 1.90864924, 36.0160459 ],\n",
       "       [ 1.68137573, 41.9143614 ],\n",
       "       ...,\n",
       "       [ 1.74201471, 30.83444979],\n",
       "       [ 1.75988585, 38.82176862],\n",
       "       [ 1.6232838 , 21.94461843]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#array de estaturas\n",
    "muestras, cluster = gm.sample(1000)\n",
    "muestras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "inside-vietnam",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_esperado(altura_edad):\n",
    "    altura = altura_edad[:,0]\n",
    "    edad = altura_edad[:,1]\n",
    "    return edad/altura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "funky-bolivia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.97"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "muestras_g = val_esperado(muestras)\n",
    "valor_esperado_g = round(np.mean(muestras_g),2)\n",
    "valor_esperado_g"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
