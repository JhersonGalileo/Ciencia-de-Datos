{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "severe-interview",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "rotary-williams",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Usuario\\anaconda3\\envs\\CDDP\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "Enabled compatitility to tf1.x\n"
     ]
    }
   ],
   "source": [
    "if tf.__version__.startswith(\"2.\"):\n",
    "    import tensorflow.compat.v1 as tf\n",
    "    tf.compat.v1.disable_v2_behavior()\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "    print(\"Enabled compatitility to tf1.x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "facial-arctic",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet = np.load('proyecto_training_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "otherwise-horizon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1460\n",
      "1168\n",
      "292\n"
     ]
    }
   ],
   "source": [
    "dataP = dataSet[:int(len(dataSet)*0.8)]\n",
    "dataA = dataSet[int(len(dataSet)*0.8):]\n",
    "print(len(dataSet))\n",
    "print(len(dataP))\n",
    "print(len(dataA))\n",
    "df = pd.DataFrame(dataP, columns = ['X0','X1','X2','X3','X4','X5'])\n",
    "dfA = pd.DataFrame(dataA, columns = ['X0','X1','X2','X3','X4','X5'])\n",
    "#print(df)\n",
    "#dfA.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "informed-heater",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VALOR DE Y\n",
    "Y = df['X0'].values\n",
    "#entrenado X1 \n",
    "X1 = df['X1'].values\n",
    "#funcionLineal(X1,Y,10000,950,0.01,0,0,'X1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-opinion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cooked-ebony",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regresion_lineal(X_1,Y_1,epochs,lr,pol_n, mini_batch):\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    g = tf.Graph()\n",
    "    \n",
    "    with g.as_default():\n",
    "        #**ejemplo de internet\n",
    "        # x and y are placeholders for our training data\n",
    "        x = tf.placeholder(\"float\", name=\"X\")\n",
    "        y = tf.placeholder(\"float\", name=\"Y\")\n",
    "        l_r = tf.placeholder(\"float\", name =\"lr\")\n",
    "\n",
    "\n",
    "        m = tf.Variable(0.0, name=\"m\")\n",
    "        b = tf.Variable(0.0, name=\"b\")\n",
    "        # Our model of y = a*x + b\n",
    "        with tf.name_scope(\"modelo\"):\n",
    "            y_hat = tf.add(tf.multiply(x, m, name =\"m.x\"), b, name=\"b\") #y = mx + b\n",
    "\n",
    "        # Our error is defined as the square of the differences\n",
    "        with tf.name_scope(\"error\"):\n",
    "            error = tf.math.pow((y - y_hat),2)/2\n",
    "            error_promedio = tf.math.reduce_mean(error)\n",
    "\n",
    "        #gradiente M\n",
    "        with tf.name_scope(\"gradienteM\"):\n",
    "            gradiente_m = tf.multiply((y_hat - y),x)\n",
    "            mean_grad_m = tf.math.reduce_mean(gradiente_m)\n",
    "\n",
    "        #gradiente B\n",
    "        with tf.name_scope(\"gradienteB\"):\n",
    "            gradiente_b = (y_hat - y) * 1\n",
    "            mean_grad_b = tf.math.reduce_mean(gradiente_b)#valor promedio del gradiente de B\n",
    "\n",
    "        error_summary = tf.summary.scalar(name =\"error_promedio\", tensor=error_promedio)\n",
    "\n",
    "        #nuevo valor de la pendiente M\n",
    "        nueva_m =  tf.assign(m, m - tf.multiply(l_r , mean_grad_m))#m\n",
    "\n",
    "        #nuevo valor del intercepto B \n",
    "        nueva_b =  tf.assign(b, b - tf.multiply(l_r , mean_grad_b))#\n",
    "\n",
    "        # Normal TensorFlow - initialize values, create a session and run the model\n",
    "        model = tf.global_variables_initializer()\n",
    "\n",
    "    with tf.Session(graph=g) as session:\n",
    "        #\n",
    "        writer = tf.summary.FileWriter('./graphs/lr='+str(lr)+'polinomio={0}'.format(pol_n), session.graph)\n",
    "        \n",
    "        session.run(model)#inicializador de variables\n",
    "        total_iteraciones = int(len(Y_1)/mini_batch)\n",
    "        \n",
    "        point = 0\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            #np.random.shuffle(X_1,Y_1)\n",
    "            \n",
    "            #dict_f = {x: X_1, y:Y_1, l_r: lr}\n",
    "            \n",
    "            for i in range(total_iteraciones):\n",
    "                #aplicando mini-batch\n",
    "                muestra_inicio = i*mini_batch\n",
    "                muestra_fin = muestra_inicio + mini_batch\n",
    "                x_mb =  np.array(X_1[muestra_inicio:muestra_fin]).reshape([-1,1])\n",
    "                y_mb = np.array(Y_1[muestra_inicio:muestra_fin]).reshape([-1,1])\n",
    "                \n",
    "                #feed_dict = {tensor_x:x_mb, tensor_y:y_mb}\n",
    "                dict_f = {x: x_mb, y:y_mb, l_r: lr}\n",
    "                #err,summary = session.run([error_promedio,error_summary], feed_dict=dict_f)\n",
    "                n_m,n_b = session.run([nueva_m,nueva_b], feed_dict=dict_f)\n",
    "                point+=1\n",
    "                writer.add_summary(summary, point)\n",
    "                #print(err,summary)\n",
    "            err,summary = session.run([error_promedio,error_summary], feed_dict=dict_f)\n",
    "        \n",
    "        print(\"NUmero de iteraciones: {0}\".format(point))\n",
    "            \n",
    "    #w_value = session.run(w)\n",
    "    #print(\"Predicted model: {a:.3f}x + {b:.3f}\".format(a=w_value[0], b=w_value[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "accessory-insurance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUmero de iteraciones: 12600\n"
     ]
    }
   ],
   "source": [
    "regresion_lineal(X1,Y,350,0.001,\"j\",32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "serious-market",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1168"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eight-missile",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "logs_base_dir = \"./graphs\"\n",
    "#os.makedirs(logs_base_dir, exist_ok=True)\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "static-settlement",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 7392), started 5:07:47 ago. (Use '!kill 7392' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e5f3b76fe81d0291\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e5f3b76fe81d0291\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir './graphs/' --port 6007"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-croatia",
   "metadata": {},
   "source": [
    "### **Experimento 1 probando un mini_batch de 2, con lr=0.001, y 50 iteraciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "upset-evanescence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUmero de iteraciones: 29200\n"
     ]
    }
   ],
   "source": [
    "### **Experimento 1 probando un mini_batch de 2, con lr=0.001, y 50 iteraciones**\n",
    "regresion_lineal(X1,Y,50,0.001,\"a\",2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "palestinian-cylinder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUmero de iteraciones: 29200\n"
     ]
    }
   ],
   "source": [
    "### **Experimento 2 probando un mini_batch de 4, con lr=0.001, y 100 iteraciones**\n",
    "regresion_lineal(X1,Y,100,0.001,\"b\",4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "apart-congo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUmero de iteraciones: 29200\n"
     ]
    }
   ],
   "source": [
    "### **Experimento 3 probando un mini_batch de 8, con lr=0.001, y 200 iteraciones**\n",
    "regresion_lineal(X1,Y,200,0.001,\"c\",8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "internal-shade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUmero de iteraciones: 29200\n"
     ]
    }
   ],
   "source": [
    "### **Experimento 4 probando un mini_batch de 16, con lr=0.001, y 400 iteraciones**\n",
    "regresion_lineal(X1,Y,400,0.001,\"d\",16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "modern-internet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUmero de iteraciones: 28800\n"
     ]
    }
   ],
   "source": [
    "### **Experimento 5 probando un mini_batch de 32, con lr=0.001, y 800 iteraciones**\n",
    "regresion_lineal(X1,Y,800,0.001,\"e\",32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "grand-theorem",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUmero de iteraciones: 29200\n"
     ]
    }
   ],
   "source": [
    "### **Experimento 6 probando un mini_batch de 2, con lr=0.01, y 50 iteraciones**\n",
    "regresion_lineal(X1,Y,50,0.01,\"f\",2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "interracial-storage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUmero de iteraciones: 29200\n"
     ]
    }
   ],
   "source": [
    "### **Experimento 7 probando un mini_batch de 4, con lr=0.01, y 100 iteraciones**\n",
    "regresion_lineal(X1,Y,100,0.01,\"g\",4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "diagnostic-group",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUmero de iteraciones: 29200\n"
     ]
    }
   ],
   "source": [
    "### **Experimento 8 probando un mini_batch de 8, con lr=0.01, y 200 iteraciones**\n",
    "regresion_lineal(X1,Y,200,0.01,\"h\",8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "metric-schema",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUmero de iteraciones: 29200\n"
     ]
    }
   ],
   "source": [
    "### **Experimento 9 probando un mini_batch de 16, con lr=0.01, y 400 iteraciones**\n",
    "regresion_lineal(X1,Y,400,0.01,\"i\",16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "prime-courtesy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUmero de iteraciones: 28800\n"
     ]
    }
   ],
   "source": [
    "### **Experimento 10 probando un mini_batch de 32, con lr=0.01, y 800 iteraciones**\n",
    "regresion_lineal(X1,Y,800,0.01,\"j\",32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "known-queens",
   "metadata": {},
   "source": [
    "utilizar un enfoque investigación científica: antes del experimento formular una hipótesis del comportamiento experado, \n",
    "ejecutar el experimento y utilizar los resultados de tensorboard para conculir.\n",
    "\n",
    "Dado que la variable utilizada tiene con coeficiente de correlacion de 0.79, se espera encontrar un modelo que minimice el error, sobre la cual se puedan hacer predicciones con un sesgo bajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-madagascar",
   "metadata": {},
   "outputs": [],
   "source": [
    "basado en los resultados experimentales obtenidos con tensorboard crear una conclusión general y elegir el mejor experimento.\n",
    "- agregar el contenido de tensorboard al notebook(pueden ser screenshots="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-museum",
   "metadata": {},
   "source": [
    "Utilizando tensorboard como visualizador de MSE, se realizo una comparativa entre los modelos similares, es decir lr =0.001 con minibatch de 2, con el modelo con lr=0.01 y mismo minibatch, asi con todos los modelos experimentados.\n",
    "\n",
    "Se puede observar que con el minibatch de 2, existe gran varianza del error en cuanto al modelo utilizado con batch gradient descent, pero que a medida que avanzan las iteraciones este modelo, el error va disminuyendo notoriamente, donde al final el sesgo visualizado se asemeja a la tendencia esperada, pero presenta mejores resultados en cuanto a sesgo el modelo con lr = 0.001.\n",
    "\n",
    "En los modelos con minibatch de 8, se presenta un comportamiento interesante, donde se puede visualizar que ambos modelos tienen la misma tendencia en cuanto a la disminución del error, pero en este caso el modelo con lr=0.01 presenta mejores resultados, dado que el sesgo se apega mas a la tendencia esperada, pero ambos modelos terminan en un punto muy similar, dadas las iteraciones realizadas.\n",
    "\n",
    "Pra el experimiento con minibatch de 32, y comparando ambos lr, se puede apreciar que el modelo que mejor representa el resultado esperado es con lr=0.01, donde la varianza del error es menor que con el modelo con lr=0.01.\n",
    "\n",
    "Habiendo analizado todos los experimentos realizados, se concluye, que el mejor modelo para validar la hipotesis es el que utliza un lr=0.001 y mini-batch de 16, \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "copyrighted-institution",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "center-lending",
   "metadata": {},
   "source": [
    "<img src=\"https://www.google.com.gt/url?sa=i&url=https%3A%2F%2Fwww.universoformulas.com%2Fmatematicas%2Fanalisis%2Ffuncion-exponencial%2F&psig=AOvVaw3Np-UMeO8iDj4kbSp945gq&ust=1623110052570000&source=images&cd=vfe&ved=0CAIQjRxqFwoTCIir_KKahPECFQAAAAAdAAAAABAD\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
